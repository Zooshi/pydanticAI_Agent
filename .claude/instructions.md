We want to build a Python Streamlit application which allows a user to upload documents. It could be PDF files, or also Markdown files, or text files, or also Word files.
The application first hashes the document and checks whether the document already exists in the qdrant vectorstore via its hash. If yes, the user gets informed that a document already exists in the Vector Store, and the application will not upload the document. Otherwise, we proceed with the document upload. This works like that.
The document should be first converted into Markdown, and then chunked based on the Markdown structure, and then embedded and stored into a vector store. For the embedding, we use OpenAI Embeddings, TextEmbeddings 3 Small model, and for the vector store we use a locally running Qdrant vector store which is running on Docker on the default port.Beside the document chunk and the embeddings, we also store metadata (e.g., of course the hash of the document, as well as the document name, as well as other relevant metadata). Feel free to propose what makes sense here. The application should also always First, check whether the Qadrant Vector Store is running and also give the user a hint in the frontend that the vector store is running. If not, it needs to start the docker container. The image is already available. There is no need to pull it. The user should also be visually informed either by a progress loading bar or something like that during the upload process and know when the upload is finished.

Also, all available documents should be displayed to the user, and he should have the option to click on a trash icon to remove one of the files from the VectorStore, which would include all relevant chunks of this file if he deletes that. In the front-end, we also have a chat input box that allows the user to chat with the uploaded documents (meaning asking questions about it). For the model here, we use qwen3:8b model, which is running on ollama on default port. We want to leverage PydanticAI framework here. So we use a PydanticAI agent which uses our ollama model. You already find a snippet from the pydanticAI docs in the "ollama_sample.py" file on how ollama works within pydanticAI framework. We also want to leverage the built-in log fire in Pydantic AI to trace the interactions with our large language model. The API keys will be provided, so just create a sample.env file during the development process. For the design of the Streamlit app, we want to use custom CSS and get it as close as possible (meaning particular colors,fonts, design but related to our app not the one in the image) to the image in our current folder named "image.png" which is inspired by NVIDIA style. If you got any questions up front or something is ambiguous or unclear, then ask first!
